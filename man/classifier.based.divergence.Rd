% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/divergences.R
\name{classifier.based.divergence}
\alias{classifier.based.divergence}
\title{Estimate Divergence Using a Classifier-based Approach}
\usage{
classifier.based.divergence(X, Y, alpha = 0.5)
}
\arguments{
\item{X}{A matrix or data frame representing the first dataset.}

\item{Y}{A matrix or data frame representing the second dataset.}

\item{alpha}{The elastic net mixing parameter, with 0 <= alpha <= 1. alpha=1 is the lasso penalty,
and alpha=0 is the ridge penalty.}
}
\value{
A numeric value representing the estimated divergence.
}
\description{
This function estimates the divergence between two datasets using a classifier-based approach.
The intuition behind this method is that if two datasets are very different, it should be
easy to train a classifier to distinguish between them, resulting in a low classification error.

The algorithm works by:
\enumerate{
\item Combining X and Y into a single dataset with labels.
\item Training a logistic regression model with elastic net regularization to classify the points.
\item Using the negative log-likelihood of the model as a proxy for divergence.
}

This approach has several advantages:
\enumerate{
\item It can handle high-dimensional data well, especially with the elastic net regularization.
\item It provides a flexible framework that can be adapted to different types of data by
choosing appropriate classification algorithms.
\item The regularization parameter alpha allows for tuning between L1 and L2 regularization,
providing control over feature selection and multicollinearity handling.
}

While not a direct measure of relative entropy, this method provides a robust way to
quantify the dissimilarity between datasets, especially in high-dimensional spaces.
}
\examples{
X <- matrix(rnorm(1000), ncol = 2)
Y <- matrix(rnorm(1000, mean = 1), ncol = 2)
result <- classifier.based.divergence(X, Y)
print(result)

}
\references{
Friedman, J., Hastie, T., & Tibshirani, R. (2010). Regularization paths for generalized linear
models via coordinate descent. Journal of statistical software, 33(1), 1.
}
