% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mabilog.R
\name{mabilog}
\alias{mabilog}
\title{Model-Averaged Binary Locally-Weighted Logistic Smoothing (MABILOG)}
\usage{
mabilog(
  x,
  y,
  y.true = NULL,
  max.iterations = 100,
  ridge.lambda = 0.002,
  max.beta = 100,
  tolerance = 1e-08,
  k.min = max(3, as.integer(0.05 * length(x))),
  k.max = as.integer((length(x) - 1)/2) - 1,
  n.bb = 100,
  p = 0.95,
  distance.kernel = 1,
  dist.normalization.factor = 1.1,
  verbose = FALSE
)
}
\arguments{
\item{x}{Numeric vector of x coordinates (predictors).}

\item{y}{Numeric vector of binary response values (0 or 1).}

\item{y.true}{Optional numeric vector of true probabilities for error calculation.}

\item{max.iterations}{Maximum number of iterations for logistic regression convergence
(default: 100).}

\item{ridge.lambda}{Ridge regression penalty parameter for stabilization
(default: 0.002).}

\item{max.beta}{Maximum allowed absolute value for regression coefficients
(default: 100.0).}

\item{tolerance}{Convergence tolerance for logistic regression
(default: 1e-8).}

\item{k.min}{Minimum number of neighbors on each side (positive integer).
Default is 5 percent of data points or 3, whichever is larger.}

\item{k.max}{Maximum number of neighbors on each side.
Default is \code{(n-1)/2 - 1} where n is the number of data points.}

\item{n.bb}{Number of Bayesian bootstrap iterations (non-negative integer).
Set to 0 to skip bootstrap (default: 100).}

\item{p}{Probability level for credible intervals (between 0 and 1, default: 0.95).}

\item{distance.kernel}{Integer specifying kernel type for distance weighting (1-10).
Common choices: 1 = Uniform, 2 = Triangular, 3 = Epanechnikov,
4 = Quartic, 5 = Tricube, 6 = Gaussian, 7 = Cosine (default: 1).}

\item{dist.normalization.factor}{Positive factor for distance normalization - must be greater than 1
(default: 1.1).}

\item{verbose}{Logical; if TRUE, prints progress information (default: FALSE).}
}
\value{
A list of class "mabilog" containing:
\item{\code{k_values}}{Vector of tested k values}
\item{\code{opt_k}}{Optimal k value selected by minimizing LOOCV error}
\item{\code{opt_k_idx}}{Index of optimal k in k_values vector}
\item{\code{k_mean_errors}}{Mean LOOCV errors for each k value}
\item{\code{k_mean_true_errors}}{Mean true errors for each k (if y.true provided)}
\item{\code{predictions}}{Model-averaged probability predictions using optimal k}
\item{\code{errors}}{Leave-one-out cross-validation errors}
\item{\code{k_predictions}}{List of predictions for each k value}
\item{\code{bb_predictions}}{Bootstrap mean predictions (if n.bb > 0)}
\item{\code{cri_L}}{Lower credible interval bounds (if n.bb > 0)}
\item{\code{cri_U}}{Upper credible interval bounds (if n.bb > 0)}
\item{\code{x_sorted}}{Input x values (sorted)}
\item{\code{y_sorted}}{Input y values (sorted by x)}
\item{\code{y_true_sorted}}{True probabilities (sorted by x, if provided)}
\item{\code{k_min}}{Minimum k value used}
\item{\code{k_max}}{Maximum k value used}
}
\description{
Implements MABILOG algorithm for robust local logistic regression on binary data,
extending the MABILO framework by incorporating model averaging with local
logistic regression and Bayesian bootstrap for uncertainty quantification.
The algorithm uses symmetric k-hop neighborhoods and kernel-weighted averaging
for predictions.
}
\details{
The MABILOG algorithm extends MABILO to binary classification problems by:
\itemize{
\item Using local weighted logistic regression instead of linear regression
\item Incorporating ridge regularization for numerical stability
\item Implementing coefficient constraints to prevent extreme predictions
\item Providing probability estimates rather than continuous predictions
}

The algorithm automatically sorts input data by x values. For each point,
it uses k-hop neighborhoods (k points on each side when available) rather
than k-nearest neighbors, providing more symmetric neighborhoods. The optimal
k is selected by minimizing mean leave-one-out cross-validation error.

The Bayesian bootstrap analysis (when n.bb > 0) provides uncertainty
quantification through credible intervals computed at the specified
probability level p.
}
\examples{
# Generate binary data with smooth probability structure
set.seed(42)
x <- seq(0, 10, length.out = 200)
true_prob <- plogis(sin(x) - 0.5)
y <- rbinom(length(x), 1, true_prob)

# Fit MABILOG model
fit <- mabilog(x, y, y.true = true_prob, k.min = 5, k.max = 20)

# Plot results
plot(x, y, col = c("red", "blue")[y + 1], pch = 19, cex = 0.5)
lines(fit$x_sorted, fit$predictions, lwd = 2)
lines(x, true_prob, col = "green", lty = 2)
legend("topright", c("Data (y=0)", "Data (y=1)", "Fitted", "True"),
       col = c("red", "blue", "black", "green"),
       pch = c(19, 19, NA, NA), lty = c(NA, NA, 1, 2))

# With bootstrap confidence intervals
\donttest{
fit_bb <- mabilog(x, y, k.min = 5, k.max = 20, n.bb = 100)
plot(x, y, col = c("red", "blue")[y + 1], pch = 19, cex = 0.5)
polygon(c(fit_bb$x_sorted, rev(fit_bb$x_sorted)),
        c(fit_bb$cri_L, rev(fit_bb$cri_U)),
        col = "gray80", border = NA)
lines(fit_bb$x_sorted, fit_bb$predictions, lwd = 2)
}

}
\seealso{
\code{\link{mabilo}} for continuous response regression,
\code{\link{predict.mabilog}} for predictions on new data,
\code{\link{plot.mabilog}} for diagnostic plots
}
