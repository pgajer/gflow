% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mabilo.R
\name{mabilo}
\alias{mabilo}
\title{Model-Averaged Locally Weighted Scatterplot Smoothing (MABILO)}
\usage{
mabilo(
  x,
  y,
  y.true = NULL,
  k.min = max(3, as.integer(0.05 * length(x))),
  k.max = NULL,
  n.bb = 100,
  p = 0.95,
  kernel.type = 7L,
  dist.normalization.factor = 1.1,
  epsilon = 1e-10,
  verbose = FALSE
)
}
\arguments{
\item{x}{Numeric vector of x coordinates.}

\item{y}{Numeric vector of y coordinates (response values).}

\item{y.true}{Optional numeric vector of true y values for error calculation.}

\item{k.min}{Minimum number of neighbors on each side (positive integer).}

\item{k.max}{Maximum number of neighbors on each side. If NULL, defaults to min((n-2)/4, max(3*k.min, 10)).}

\item{n.bb}{Number of Bayesian bootstrap iterations (non-negative integer). Set to 0 to skip bootstrap.}

\item{p}{Probability level for credible intervals (between 0 and 1).}

\item{kernel.type}{Integer; kernel type for weight calculation:
\itemize{
\item 1: Epanechnikov
\item 2: Triangular
\item 3: Truncated exponential
\item 4: Laplace
\item 5: Normal
\item 6: Biweight
\item 7: Tricube (default)
\item 8: cosine
\item 9: hyperbolic
\item 10: constant
}
Default is 7.}

\item{dist.normalization.factor}{Positive number for distance normalization (default: 1.1).}

\item{epsilon}{Small positive number for numerical stability (default: 1e-10).}

\item{verbose}{Logical; if TRUE, prints progress information.}
}
\value{
A list of class "mabilo" containing:
\itemize{
\item k_values - Vector of tested k values
\item opt_k - Optimal k value for model averaging
\item opt_k_idx - Index of optimal k value
\item k_mean_errors - Mean LOOCV errors for each k
\item k_mean_true_errors - Mean true errors if y.true provided
\item ma_predictions - Model-averaged predictions using optimal k
\item k_predictions - Model-averaged predictions for all k values
\item bb_predictions - Central location of bootstrap estimates (if n.bb > 0)
\item cri_L - Lower bounds of credible intervals (if n.bb > 0)
\item cri_U - Upper bounds of credible intervals (if n.bb > 0)
\item x_sorted - Input x values sorted in ascending order
\item y_sorted - y values sorted corresponding to x_sorted
\item y_true_sorted - y.true values sorted corresponding to x_sorted
\item k_min - Minimum neighborhood size used
\item k_max - Maximum neighborhood size used
}
}
\description{
Implements MABILO algorithm for robust local regression, extending LOWESS by incorporating
model averaging and Bayesian bootstrap for uncertainty quantification. The algorithm uses
symmetric k-hop neighborhoods and kernel-weighted averaging for predictions.
}
\details{
The function automatically sorts input data by x values. For each point, it uses
k-hop neighborhoods (k points on each side when available) rather than k-nearest
neighbors, providing more symmetric neighborhoods. The optimal k is selected by
minimizing mean LOOCV errors.

The Bayesian bootstrap analysis (when n.bb > 0) provides uncertainty
quantification through credible intervals computed at the specified
probability level p. Note that setting n.bb > 0 increases computation time
proportionally, as the algorithm must be run n.bb times with different weight
configurations.
\subsection{Bayesian Bootstrap}{

The Bayesian bootstrap, introduced by Rubin (1981), is a variant of the classical
bootstrap that generates smooth posterior distributions. Instead of resampling with
replacement (which gives discrete weights n_i/n where n_i is the number of times
observation i is selected), the Bayesian bootstrap assigns continuous weights to
each observation.

Specifically, for each bootstrap iteration:
\enumerate{
\item Generate weights (w_1, ..., w_n) from a Dirichlet(1, 1, ..., 1) distribution
\item These weights sum to 1 and provide a smooth reweighting of the data
\item Compute the MABILO estimate using these weights
}

This approach has several advantages:
\itemize{
\item Provides smooth posterior distributions rather than discrete ones
\item Every observation contributes to each bootstrap sample (with varying weights)
\item Naturally incorporates uncertainty in a Bayesian framework
\item Often produces less variable estimates than classical bootstrap
}

The credible intervals computed from Bayesian bootstrap samples can be interpreted
as Bayesian posterior intervals under a noninformative prior. See Rubin (1981)
"The Bayesian Bootstrap" and Lo (1987) "A Large Sample Study of the Bayesian
Bootstrap" for theoretical details.
}
}
\examples{
# Basic usage
x <- seq(0, 10, length.out = 100)
y <- sin(x) + rnorm(100, 0, 0.1)
fit <- mabilo(x, y, k.min = 3, k.max = 10)
plot(x, y)
lines(x, fit$predictions, col = "red")

# With Bayesian bootstrap
fit_bb <- mabilo(x, y, k.min = 3, k.max = 10, n.bb = 100, p = 0.95)
lines(x, fit_bb$cri_L, col = "blue", lty = 2)
lines(x, fit_bb$cri_U, col = "blue", lty = 2)

}
\references{
Rubin, D.B. (1981). The Bayesian Bootstrap. The Annals of Statistics, 9(1), 130-134.

Lo, A.Y. (1987). A Large Sample Study of the Bayesian Bootstrap. The Annals of
Statistics, 15(1), 360-375.

Newton, M.A. & Raftery, A.E. (1994). Approximate Bayesian Inference with the
Weighted Likelihood Bootstrap. Journal of the Royal Statistical Society, Series B,
56(1), 3-48.
}
