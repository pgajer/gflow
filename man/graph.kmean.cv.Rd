% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/graph_kmean.R
\name{graph.kmean.cv}
\alias{graph.kmean.cv}
\title{Cross-validation for Kernel-weighted Graph Neighbor Mean}
\usage{
graph.kmean.cv(
  graph,
  edge.lengths,
  y,
  kernel = 1,
  dist.normalization.factor = 1.01,
  n.CVs = 10,
  n.CV.folds = 10,
  seed = 0,
  use.weighted.MAD.error = FALSE
)
}
\arguments{
\item{graph}{A list of integer vectors representing the adjacency list
(1-based indexing).}

\item{edge.lengths}{A list of numeric vectors containing edge lengths.
Structure must match \code{graph}.}

\item{y}{A numeric vector of response values at each vertex.}

\item{kernel}{Either an integer (1-4) or a character string specifying the
kernel function:
\itemize{
\item 1 or "epanechnikov" = Epanechnikov kernel (default)
\item 2 or "triangular" = Triangular kernel
\item 3 or "truncated_exponential" = Truncated exponential kernel
\item 4 or "normal" = Normal (Gaussian) kernel
}}

\item{dist.normalization.factor}{A positive numeric value (>= 1) for
distance normalization. Default is 1.01.}

\item{n.CVs}{Number of cross-validation iterations. Default is 10.}

\item{n.CV.folds}{Number of folds for each CV iteration. Must be >= 2.
Default is 10.}

\item{seed}{Integer seed for reproducibility. Default is 0.}

\item{use.weighted.MAD.error}{Logical; if TRUE, uses weighted Mean Absolute
Deviation for binary classification problems to handle class imbalance.
Default is FALSE.}
}
\value{
A numeric vector of cross-validation errors for each vertex. Values
may be NaN for vertices that were excluded in all CV iterations.
}
\description{
Performs k-fold cross-validation to evaluate the performance of the
kernel-weighted neighbor mean algorithm on a graph. This function helps in
selecting optimal parameters such as the kernel type and distance
normalization factor.
}
\details{
The function performs repeated k-fold cross-validation. In each iteration,
the data is randomly partitioned into k folds. Each fold is held out once
while the model is trained on the remaining folds, and predictions are made
for the held-out vertices.

When \code{use.weighted.MAD.error = TRUE}, the function applies class
weights to handle imbalanced binary classification:
\itemize{
\item Weight for class 0: 1 / (1 - q)
\item Weight for class 1: 1 / q
}
where q is the proportion of class 1 samples.
}
\examples{
# Triangle graph example
graph <- list(c(2, 3), c(1, 3), c(1, 2))
edge.lengths <- list(c(0.1, 0.2), c(0.1, 0.3), c(0.2, 0.3))
y <- c(1.0, 2.0, 3.0)

# Perform cross-validation
cv.errors <- graph.kmean.cv(graph, edge.lengths, y,
                            kernel = "epanechnikov",
                            n.CVs = 5, n.CV.folds = 3)
print(cv.errors)

}
\seealso{
\code{\link{graph.kmean}} for the main function
}
